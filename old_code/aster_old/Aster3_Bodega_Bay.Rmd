---
ftitle: "Aster3_Bodega_Bay"
author: "Helen Payne"
date: "2024-09-08"
output: html_document
---


#BODEGA BAY
##Generation 1 2022
```{r}
library(tidyverse)
library(readr)
library(dplyr)
library(stringr)
library(here)

#read in the data and change the name to #surv_to_fruitpod from surv_to_fruitprods
#BB_22 <- read_csv(here::here("data_sheets", "compiled_sheets", "BB_mastersheet_full_2022.csv")) %>%
#  rename_at(vars(55), ~"surv_to_fruitpod")
         
#colnames(BB_22)
      

BB_22 <- read_csv(here::here("data_sheets", "compiled_sheets", "BB_mastersheet_full_2022.csv")) %>%
  rename_at(vars(56), ~"surv_to_fruitpod") %>%
  mutate(
    # Construct sample_ID conditionally
    sample_ID = str_c(Year, Recipient, Gen, str_pad(Location, width = 3, pad = "0"), Plant_ID, sep = "-"),
    # Replace leading underscores in sample_ID with hyphens
    sample_ID = str_replace(sample_ID, "^([^_]*)_", "\\1-")
  ) %>%
  dplyr::select("Location", "Donor", "Recipient", "sample_ID", "surv_to_flower", "any_FitP", "total_fruits", "closed_fruits", "mean_seeds_per_fruit") %>%
  mutate(any_FitP = ifelse(any_FitP == TRUE, 1, 0)) %>%
  filter(!(Location %in% c("W1", "W2"))) %>%
  mutate(surv_to_flower = ifelse(total_fruits > 0 & surv_to_flower == 0, 1, surv_to_flower)) %>%
  mutate(any_FitP = ifelse(surv_to_flower == 0, 0, any_FitP))

BB_22$mean_seeds_per_fruit <- dplyr::case_when(
  BB_22$mean_seeds_per_fruit > 0 & BB_22$mean_seeds_per_fruit < 1 ~ 1,
  BB_22$mean_seeds_per_fruit >= 1 ~ round(BB_22$mean_seeds_per_fruit),
  TRUE ~ BB_22$mean_seeds_per_fruit
)

```


```{r}
#make NAs for other life history stages zero
BB_22$surv_to_flower[is.na(BB_22$surv_to_flower)] <- 0
BB_22$total_fruits[is.na(BB_22$total_fruits)]<-0
BB_22$closed_fruits[is.na(BB_22$closed_fruits)]<-0
BB_22$mean_seeds_per_fruit[is.na(BB_22$mean_seeds_per_fruit)]<-0

# Define the update_zeros function
## Determines survival info
update_zeros <- function(df) {
  for (i in 1:nrow(df)) {
    if (df$surv_to_flower[i] == 0) {
      df$total_fruits[i] <- 0
      df$closed_fruits[i] <- 0
      df$mean_seeds_per_fruit[i] <- 0
    }
    if (df$total_fruits[i] == 0) {
      df$closed_fruits[i] <- 0
      df$mean_seeds_per_fruit[i] <- 0
    }
    if (df$closed_fruits[i] <- 0) {
      df$mean_seeds_per_fruit[i] <- 0
    }
  return(df)
  }}

# Apply the function to the dataset
BB_22 <- update_zeros(BB_22)
```

```{r}
#check for nonsense data
subset(BB_22, mean_seeds_per_fruit > 0 & surv_to_flower == 0)
subset(BB_22, mean_seeds_per_fruit > 0 & any_FitP == 0)
subset(BB_22, mean_seeds_per_fruit > 0 & total_fruits == 0)
subset(BB_22, mean_seeds_per_fruit > 0 & closed_fruits == 0)

#Make  sire and dam factors
BB_22$Donor <- as.factor(BB_22$Donor)
BB_22$Recipient <- as.factor(BB_22$Recipient)

#number that germinated from table 1
BB_22 %>%
  mutate(surv_to_flower = as.factor(surv_to_flower)) %>% 
  group_by(surv_to_flower) %>% 
  count() #I don't think Devin included plants that didn't flower.. we need to fix this

#distinct number of dams
BB_22 %>%
  distinct(Recipient) %>%
  count()

#distinct # sires
BB_22  %>%
  distinct(Donor) %>%
  count()

#number of dams, and number of individuals for each dam
NDS<-BB_22 %>%
  group_by(Recipient, Donor) %>% 
  count()
```


#Creating new rows for every fruit so we can subset the data twice
```{r}
expand_rows <- function(df) {
  # Create an empty list to store the expanded rows
  expanded_rows <- list()
  
  # Loop through each row of the data frame
  for (i in 1:nrow(df)) {
    # Extract the values of 'closed_fruits' and 'total_fruits' for the current row
    c <- df$closed_fruits[i]
    t <- df$total_fruits[i]
    
    # Create a new data frame with 't' rows if t > 0, otherwise just copy the row once
    new_rows <- df[i, , drop = FALSE] # Copy the row
    
    if (t > 0) {
      # Replicate the row 't' times
      expanded_data <- new_rows[rep(seq_len(nrow(new_rows)), t), ]
      # Assign 'closed_fruits' to 1 for the first 'c' rows, and 0 for the remaining
      expanded_data$closed_fruits <- c(rep(1, c), rep(0, t - c))
    } else {
      # If 'total_fruits' is 0, keep the row as it is
      expanded_data <- new_rows
    }
    
    # Add the new rows to the list
    expanded_rows[[i]] <- expanded_data
  }
  
  # Combine the list of data frames into a single data frame
  expanded_df <- do.call(rbind, expanded_rows)
  
  return(expanded_df)
}

# Apply the function to your data frame
expanded_BB_22 <- expand_rows(BB_22)

expanded_BB_22$total_fruits <- ifelse(expanded_BB_22$total_fruits > 0, 1, expanded_BB_22$total_fruits)

```


###Set up aster 
```{r}
library(aster)
library(reshape2)

#the "vars" are the nodes in the aster graphical model.   
vars<-c("surv_to_flower", "any_FitP", "total_fruits", "closed_fruits", "mean_seeds_per_fruit")

#convert to a dataframe for reshape to work
expanded_BB_22 <- as.data.frame(expanded_BB_22)

#Reshape BB to longform. "varying" notes the set of variables that will be converted to longform and named in "timevar" under one column of varb. "Times" says to use vars for the newly created column varb 
BB22_aster <- reshape(expanded_BB_22, varying = list(vars), direction = "long", timevar = "varb",times = as.factor(vars), v.names = "resp")

#####Check that the reshape worked 
#If it did the number of rows will be the same 
nrow(BB22_aster)
nrow(expanded_BB_22)*length(vars)


#####Designate fitness variable, "mean_seeds_per_fruit", which is the final node 
#grep1 is like a search function
fit<-grepl("mean_seeds_per_fruit", as.character(BB22_aster$varb))
fit<-as.numeric(fit)
BB22_aster$fit<-fit

#####Check "mean_seeds_per_fruit", is designated as the fitness variable 
with(BB22_aster, sort(unique(as.character(varb)[fit==0])))
with(BB22_aster, sort(unique(as.character(varb)[fit==1])))

#####Add "root" to ML18_aster files where value is 1 
BB22_aster <- data.frame(BB22_aster, root=1)

#####Set graphical node and distribution for fitness nodes(preds) 
names(BB22_aster)

#pred is nodes. There are 5 nodes, so five preds.
pred <- c(0,1,2,2,3)

#fam assigns a distribution to each node. 1= bernoulli, 2= poission. The subsampling node (node #2 in pred) is binomial. Bernouli is a specific type of binomial so the assignment for family distribution is the same
fam<-c(1,1,2,1,2)
```


```{r}
library(MASS)

#check distribution of non-Bernoulli nodes
#Evaluate distribution of total pods
#first subset for those that survived to flowering 
BB22_flwr<-subset(expanded_BB_22, surv_to_flower>0)

#evaluate the distribution of total_fruits 
hist(BB22_flwr$mean_seeds_per_fruit)

#get parameters for a negative binomial distribution
BB22.param <- fitdistr(BB22_flwr$mean_seeds_per_fruit, "negative binomial") 


#get a random distribution with the parameters from you data and plot a histogram. Do that for poisson and negative bionoimal and compare against the histogram for total pods to see which fits the best 
#nbinomial??
hist(rnbinom(1891, size = 0.173, mu=1.14))
hist(rpois(1891, lambda=1.14))

#evaluate filled seeds node. Proceed as outlined aBBve 
BB22_total_fruit<-subset(expanded_BB_22, total_fruits>0)
hist(BB22_total_fruit$mean_seeds_per_fruit)
BB22.param2 <- fitdistr(BB22_total_fruit$mean_seeds_per_fruit, "negative binomial") 

hist(rnbinom(672, size = 1.55, mu=3.21))
hist(rpois(672, lambda=3.21))


#evaluate filled seeds node. Proceed as outlined aBBve 
#poisson is better
BB22_closed_fruit<-subset(expanded_BB_22, closed_fruits>0)
hist(BB22_closed_fruit$mean_seeds_per_fruit)
BB22.param3 <- fitdistr(BB22_closed_fruit$mean_seeds_per_fruit, "negative binomial") 

hist(rnbinom(470, size = 2.27, mu=3.22))
hist(rpois(470, lambda=3.22))
```

###Random effects aster model
```{r}
####Testing for Donor and Recipient significance
#Donor is zero with Recipient
Both_BB22 <- reaster(resp ~ fit + varb + fit:Location, random = list(Donor = ~0 + 
    fit:Donor, Recipient = ~0 + fit:Recipient), pred = pred, fam = fam, varvar = varb, 
    idvar = id, root = root, data = BB22_aster)
summary(Both_BB22)

#Call:
#reaster.formula(fixed = resp ~ fit + varb + fit:Location, random = list(Donor = ~0 + 
#    fit:Donor, Recipient = ~0 + fit:Recipient), pred = pred, 
#    fam = fam, varvar = varb, idvar = id, root = root, data = BB22_aster)


#Fixed Effects:
#                     Estimate Std. Error z value Pr(>|z|)    
#(Intercept)         0.2444615  0.0632135   3.867  0.00011 ***
#fit                 0.7811175  0.0745314  10.480  < 2e-16 ***
#varbclosed_fruits  -0.1785035  0.1137620  -1.569  0.11663    
#varbsurv_to_flower -0.4350734  0.0864597  -5.032 4.85e-07 ***
#varbtotal_fruits   -2.5744740  0.1093568 -23.542  < 2e-16 ***
#fit:Location       -0.0009062  0.0002071  -4.376 1.21e-05 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Square Roots of Variance Components (P-values are one-tailed):
#          Estimate Std. Error z value Pr(>|z|)/2    
#Donor      0.06745    0.04537   1.487     0.0685 .  
#Recipient  0.18671    0.02404   7.767   4.02e-15 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


#Check for the effect of Donor alone. Significant. 
Donor_BB22<- reaster(resp ~ fit + varb + fit:Location, random = list(Donor = ~0 + 
    fit:Donor), pred = pred, fam = fam, varvar = varb, 
    idvar = id, root = root, data = BB22_aster)
summary(Donor_BB22)

#Call:
#reaster.formula(fixed = resp ~ fit + varb + fit:Location, random = list(Donor = ~0 + 
#    fit:Donor), pred = pred, fam = fam, varvar = varb, idvar = id, 
#    root = root, data = BB22_aster)


#Fixed Effects:
#                     Estimate Std. Error z value Pr(>|z|)    
#(Intercept)         0.2139232  0.0634820   3.370 0.000752 ***
#fit                 0.8874663  0.0738199  12.022  < 2e-16 ***
#varbclosed_fruits  -0.1479652  0.1139114  -1.299 0.193961    
#varbsurv_to_flower -0.4045351  0.0866562  -4.668 3.04e-06 ***
#varbtotal_fruits   -2.6068053  0.1102361 -23.647  < 2e-16 ***
#fit:Location       -0.0010117  0.0001968  -5.140 2.75e-07 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Square Roots of Variance Components (P-values are one-tailed):
#      Estimate Std. Error z value Pr(>|z|)/2    
#Donor  0.15250    0.02219   6.872   3.16e-12 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Check for the effect of Recipient alone. Significant. 
Recipient_BB22<- reaster(resp ~ varb + fit, random = list(Recipient = ~0 + 
    fit:Recipient), pred = pred, fam = fam, varvar = varb, 
    idvar = id, root = root, data = BB22_aster)

summary(Recipient_BB22)

#Call:
#reaster.formula(fixed = resp ~ varb + fit, random = list(Recipient = ~0 + 
#    fit:Recipient), pred = pred, fam = fam, varvar = varb, idvar = id, 
#    root = root, data = BB22_aster)


#Fixed Effects:
#                         Estimate Std. Error z value Pr(>|z|)    
#(Intercept)               0.24068    0.06325   3.805 0.000142 ***
#varbclosed_fruits        -0.17472    0.11378  -1.536 0.124634    
#varbmean_seeds_per_fruit  0.72004    0.07340   9.810  < 2e-16 ***
#varbsurv_to_flower       -0.43129    0.08649  -4.987 6.14e-07 ***
#varbtotal_fruits         -2.57879    0.10946 -23.558  < 2e-16 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Square Roots of Variance Components (P-values are one-tailed):
#          Estimate Std. Error z value Pr(>|z|)/2    
#Recipient  0.20122    0.02002   10.05     <2e-16 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1



####Combine Sire and Dam into one random effect, `Parental`. The estimates are of similar magnitude 
modmat.Donor <- model.matrix(~ 0 + fit:Donor, BB22_aster)
modmat.Recipient <- model.matrix(~ 0 + fit:Recipient, BB22_aster)
modmat.donorrecipient <- cbind(modmat.Donor,modmat.Recipient)

rout_BB22 <- reaster(resp ~ fit + varb, list(Parental = ~ 0 + modmat.donorrecipient),pred, fam, varb, id, root, data = BB22_aster)
sout_BB22 <-summary(rout_BB22)
sout_BB22

save(rout_BB22, file = "rout_BB22.rdata")

#Call:
#reaster.formula(fixed = resp ~ fit + varb, random = list(Parental = ~0 + 
#    modmat.donorrecipient), pred = pred, fam = fam, varvar = varb, 
#    idvar = id, root = root, data = BB22_aster)


#Fixed Effects:
#                   Estimate Std. Error z value Pr(>|z|)    
#(Intercept)         0.24022    0.06326   3.798 0.000146 ***
#fit                 0.71770    0.07604   9.439  < 2e-16 ***
#varbclosed_fruits  -0.17426    0.11379  -1.531 0.125651    
#varbsurv_to_flower -0.43083    0.08649  -4.981 6.32e-07 ***
#varbtotal_fruits   -2.57903    0.10948 -23.558  < 2e-16 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Square Roots of Variance Components (P-values are one-tailed):
#         Estimate Std. Error z value Pr(>|z|)/2    
#Parental  0.15386    0.01633   9.421     <2e-16 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


#model comparison for significance of Location. Significant.
rout_BB22_2 <- reaster(resp ~ fit + varb + fit:Location, list(Parental = ~ 0 + modmat.donorrecipient),
    pred, fam, varb, id, root, data = BB22_aster)
sout_BB22_2 <-summary(rout_BB22_2)
sout_BB22_2

#Call:
#reaster.formula(fixed = resp ~ fit + varb + fit:Location, random = list(Parental = ~0 + 
#    modmat.donorrecipient), pred = pred, fam = fam, varvar = varb, 
#    idvar = id, root = root, data = BB22_aster)


#Fixed Effects:
#                     Estimate Std. Error z value Pr(>|z|)    
#(Intercept)         0.2439031  0.0632212   3.858 0.000114 ***
#fit                 0.7812624  0.0765745  10.203  < 2e-16 ***
#varbclosed_fruits  -0.1779451  0.1137663  -1.564 0.117787    
#varbsurv_to_flower -0.4345150  0.0864653  -5.025 5.03e-07 ***
#varbtotal_fruits   -2.5748513  0.1093723 -23.542  < 2e-16 ***
#fit:Location       -0.0009227  0.0002076  -4.444 8.84e-06 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Square Roots of Variance Components (P-values are one-tailed):
#         Estimate Std. Error z value Pr(>|z|)/2    
#Parental  0.15066    0.01616   9.323     <2e-16 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


anova(rout_BB22, rout_BB22_2)

#Analysis of Deviance Table

#Model 1: resp ~ fit + varb, ~0 + modmat.donorrecipient
#Model 2: resp ~ fit + varb + fit:Location, ~0 + modmat.donorrecipient
#  Mod Df Fix Mod Df Rand Mod Dev Df Fix Df Rand Deviance    P-value
#1          5           1  -10427                                   
#2          6           1  -10407      1       0   20.122 7.2655e-06


####Now look at parameter estimates to be sure we have the model intended.
sout_BB22 <-summary(rout_BB22)
sout_BB22
```

###Mapping function 
```{r}
#following Geyer et al. 2022
library(numDeriv)
fishinv<-solve(sout_BB22_2$fisher)
map.factory <- function(rout, is.subsamp) {
  stopifnot(inherits(rout, "reaster"))
  stopifnot(is.logical(is.subsamp))
  aout <- rout$obj
  stopifnot(inherits(aout, "aster"))
  nnode <- ncol(aout$x)
  if (nnode != length(is.subsamp))
    stop("length(is.subsamp) not the number of nodes in the aster graph")
  alpha <- rout$alpha
  ifit <- which(names(alpha) == "fit")
  if (length(ifit) != 1)
    stop("no fixed effect named fit")
  modmat <- rout$obj$modmat[1, , , drop = FALSE]
  # set root = 1
  root <- array(1, dim = dim(modmat)[1:2])
  x <- aout$x[1, c(1:5)] # added, 5 is the number of nodes 
  # return map function
  function (b) {
    stopifnot(is.numeric(b))
    stopifnot(is.finite(b))
    stopifnot(length(b) == 1)
    alpha[ifit] <- alpha[ifit] + b
    xi <- predict(
      aout,
      x = x, # added
      newcoef = alpha,
      modmat = modmat,
      root = root,
      model.type = "conditional",
      is.always.parameter = TRUE)
  
    xi <- matrix(xi, ncol = nnode)
    # always use drop = FALSE unless you are sure you don't want that
    # here if we omit drop = FALSE and there is only one non-subsampling
    # node, the code will break (apply will give an error)
    xi <- xi[,!is.subsamp, drop = FALSE]
    mu <- apply(xi, 1, prod) #every individual
    # mu is unconditional mean values for model without subsampling
    # in this application all components mu are the same because no
    # covariates except varb, so just return only one
    mu[1] 
  }
}

map <- map.factory(rout_BB22_2, vars %in% c("any_FitP", "closed_fruits"))

#MEAN FITNESS
mf<-map(0)
mf
#0.7024933

#ADDITIVE GENETIC VARIANCE FOR FITNESS
vaw <- rout_BB22_2$sigma["Parental"]^2 * grad(map, 0)^2
# get rid of name
vaw <- as.numeric(vaw)
vaw <- vaw * 4
vaw
#0.7932965

####FFTNS
fftns <- vaw / mf
fftns
#1.129258

#prediction of progeny generation mean fitness
mf+fftns
#1.831752

# get SE
map.factory.too <- function(rout, is.subsamp) {
  stopifnot(inherits(rout, "reaster"))
  stopifnot(is.logical(is.subsamp))
  aout <- rout$obj
  stopifnot(inherits(aout, "aster"))
  nnode <- ncol(aout$x)
  if (nnode != length(is.subsamp))
    stop("length(is.subsamp) not the number of nodes in the aster graph")
  alpha <- rout$alpha
  ifit <- which(names(alpha) == "fit")
  if (length(ifit) != 1)
    stop("no fixed effect named fit")
  # modmat for one individual. Taking the first row of modmat- there is one row for each individual
  modmat <- rout$obj$modmat[1, , , drop = FALSE] #this only takes the first row 
  # set root = 1
  root <- array(1, dim = dim(modmat)[1:2])
  x <- aout$x[1, c(1:5)] # added, second number is number of nodes 
  # return map function
  function (balpha) {
    stopifnot(is.numeric(balpha))
    stopifnot(is.finite(balpha))
    stopifnot(length(balpha) == 1 + length(alpha))
    b <- balpha[1]
    alpha <- balpha[-1]
    alpha[ifit] <- alpha[ifit] + b
    xi <- predict(
      aout,
      x = x, # added
      newcoef = alpha,
      modmat = modmat,
      root = root,
      model.type = "conditional",
      is.always.parameter = TRUE
    )
    xi <- matrix(xi, ncol = nnode)
    xi <- xi[,!is.subsamp, drop = FALSE]
    mu <- apply(xi, 1, prod)
    # mu is unconditional mean values for model without subsampling
    mu[1]
  }
}

map.too <- map.factory.too(rout_BB22_2, vars %in% c("any_FitP", "closed_fruits"))

#centering sire on zero
balpha.hat <- c(0, rout_BB22_2$alpha)

map.too(balpha.hat)
#0.7024933

all.equal(map(0), map.too(balpha.hat))

#first and second derivatives
g<-grad(map.too, balpha.hat)

#calculates the nxn matrix
h <- hessian(map.too, balpha.hat)

#these are partial derivatives
dmu.db <- g[1]
dmu.dalpha <- g[-1]
d2mu.db.dalpha <- h[1, -1]

# give names to the estimators in our formulas
mu.hat <- map.too(balpha.hat)
nu.hat <- rout_BB22_2$nu["Parental"]

#FFTNS SE
#calculations for the gradient vector of the FFTNS prediction with respect to the parameters of the models (fixed effects and variance components) 
#zero removed
dfftns <- c(- 4 * nu.hat * dmu.dalpha * dmu.db^2 / mu.hat^2 +
8 * nu.hat * d2mu.db.dalpha / mu.hat, 4 * dmu.db^2 / mu.hat)

#And apply the delta method.
fftns.se <- t(dfftns) %*% fishinv %*% dfftns
fftns.se <- sqrt(as.vector(fftns.se))
fftns.se
#0.2509166

#ADDITIVE GENETIC VARIANCE SE 
#calculate the gradient vector VA(W) with respect to the parameters of the model using these formulae
dvaw <- c(8 * nu.hat * d2mu.db.dalpha, 4 * dmu.db^2)

#And then apply the delta method to get standard errors for this estimator
vaw.se <- t(dvaw) %*% fishinv %*% dvaw
vaw.se <- sqrt(as.vector(vaw.se))
vaw.se
#0.1636205

#MEAN FITNESS SE
dmf <- c(dmu.dalpha, 0)
mf.se <- t(dmf) %*% fishinv %*% dmf
mf.se <- sqrt(as.vector(mf.se))
mf.se
#0.1035591
```

###breeding values 
```{r}
#extract breeding values
bhat <- rout_BB22_2$b 
bhat.Donor<- bhat[grep("Donor", names(bhat))]

#check this is the correct number of sires (44)
length(bhat.Donor)

#convert canonical values to mean value parameter values using mapping function. "total_pods_collected" is the subsampling node 
map <- map.factory(rout_BB22_2, vars %in% c("any_FitP", "closed_fruits"))
vectorized.map <- Vectorize(map)
curve(vectorized.map, from = -1 / 2, to = 1/2, xlab="b", ylab=expression(mu(b)))

#breeding values for sire groups on the mean value parameter scale 
bhat.Donor.mu <- vectorized.map(bhat.Donor)
bhat.Donor.mu<-as.data.frame(bhat.Donor.mu)
write.csv(bhat.Donor.mu, "BB22_bhat.Donor.mu.csv")

#plot the distribution of breeding values
# Extract the numeric column from bhat.Donor.mu
numeric_values <- bhat.Donor.mu[["bhat.Donor.mu"]]  # Column name is the same as the data frame name

# Calculate and plot the density
prob_den <- density(numeric_values)
plot(prob_den)
```

#BLUE OAK RANCH
##Generation 1 2023
```{r}
library(tidyverse)

#load year 2 (2023) life history data for BB site
BB_23 <- read_csv(here::here("data_sheets", "compiled_sheets", "BB_mastersheet_full_2023.csv")) %>%
  dplyr::select("Location", "Gen", "Donor", "Recipient", "sample_ID", "surv_to_flower", "F_plant", "total_fruits", "closed_fruits", "mean_seeds_per_fruit", "msm_all") %>%
  mutate(F_plant = ifelse(F_plant == TRUE, 1, 0)) %>%
  mutate(surv_to_flower = ifelse(total_fruits > 0 & surv_to_flower == 0, 1, surv_to_flower)) %>%
  mutate(F_plant = ifelse(surv_to_flower == 0, 0, F_plant))

BB_23$mean_seeds_per_fruit <- dplyr::case_when(
  BB_23$mean_seeds_per_fruit > 0 & BB_23$mean_seeds_per_fruit < 1 ~ 1,
  BB_23$mean_seeds_per_fruit >= 1 ~ round(BB_23$mean_seeds_per_fruit),
  TRUE ~ BB_23$mean_seeds_per_fruit
)
```


```{r}
####make NAs for other life history stages zero
BB_23[is.na(BB_23$surv_to_flower),]$surv_to_flower <- 0
BB_23[is.na(BB_23$total_fruits),]$total_fruits <- 0
BB_23[is.na(BB_23$closed_fruits),]$closed_fruits <- 0
BB_23[is.na(BB_23$mean_seeds_per_fruit),]$mean_seeds_per_fruit <- 0
BB_23[is.na(BB_23$F_plant),]$F_plant <- 0

####check for nonsense data
subset(BB_23, mean_seeds_per_fruit > 0 & surv_to_flower  == 0)
subset(BB_23, mean_seeds_per_fruit > 0 & total_fruits == 0)
subset(BB_23, mean_seeds_per_fruit > 0 & closed_fruits ==0)
subset(BB_23, mean_seeds_per_fruit > 0 & mean_seeds_per_fruit ==0)
subset(BB_23, closed_fruits > total_fruits)
subset(BB_23, total_fruits > 0 & surv_to_flower  == 0)


#make factors
BB_23$Donor <- as.factor(BB_23$Donor)
BB_23$Recipient <- as.factor(BB_23$Recipient)
BB_23$Gen<-as.factor(BB_23$Gen)
```

```{r}
# Enforce logical constraints in your data

# Condition 1: If surv_to_flower is 0, then total_fruits, closed_fruits, and mean_seeds_per_fruit should be 0
BB_23$surv_to_flower[BB_23$surv_to_flower == 0] <- 0
BB_23$total_fruits[BB_23$surv_to_flower == 0] <- 0
BB_23$closed_fruits[BB_23$surv_to_flower == 0] <- 0
BB_23$mean_seeds_per_fruit[BB_23$surv_to_flower == 0] <- 0

# Condition 2: If total_fruits is 0, then closed_fruits and mean_seeds_per_fruit should be 0
BB_23$closed_fruits[BB_23$total_fruits == 0] <- 0
BB_23$mean_seeds_per_fruit[BB_23$total_fruits == 0] <- 0

# Condition 3: closed_fruits should be less than or equal to total_fruits
BB_23$closed_fruits <- pmin(BB_23$closed_fruits, BB_23$total_fruits)

# Condition 4: If closed_fruits is 0, then mean_seeds_per_fruit should be 0
BB_23$mean_seeds_per_fruit[BB_23$closed_fruits == 0] <- 0
```

####Germination in parental vs progeny
```{r}
library(tidyverse)
#data for table 1
#counts the number of Recipients in parental and progeny generation
BB_23 %>%
  group_by(Gen) %>% 
  distinct(Recipient) %>%
  arrange(Gen, Recipient) %>%
  count()

#counts the number of Donors in each group. For progeny number of sires is grand-Donors as they were open pollinated in the field 
BB_23 %>%
  group_by(Gen) %>% 
  distinct(Donor) %>%
  count()

BB_23 %>%
  group_by(Gen, Recipient, Donor) %>% 
  count()
```

####Seed weight
```{r}
#regress fitness on seed weight
#Only the first planting position contained the weighed seed hence slice by 1 to get the planting position with .1
library(dplyr)
library(ggplot2)

seedWgt_BB <- BB_23 %>%
  dplyr::select(sample_ID, Recipient, Gen, surv_to_flower, msm_all, mean_seeds_per_fruit) %>%
  filter(!is.na(msm_all)) %>%
  group_by(Recipient) %>%
  slice(1)

# t-test of seed weight between generations
t.test(subset(seedWgt_BB, Gen == "G1")$msm_all, subset(seedWgt_BB, Gen == "G2")$msm_all)

#	Welch Two Sample t-test

#data:  subset(seedWgt_BB, Gen == "G1")$msm_all and subset(seedWgt_BB, Gen == "G2")$msm_all
#t = -1.6437, df = 57.425, p-value = 0.1057
#alternative hypothesis: true difference in means is not equal to 0
#95 percent confidence interval:
# -1.1519567  0.1132587
#sample estimates:
#mean of x mean of y 
# 3.797114  4.316463 

#average seed weight of progeny and parental
seedWgt_BB%>%
  group_by(Gen) %>%
  summarise(Average=mean(msm_all))
```


####check distributions
```{r}

BB23_aster_a<-subset(BB_23, Gen=="G1")
library(MASS)

#total_fruits
#negative binomial is better
BByr2_flwr<-subset(BB23_aster_a, surv_to_flower>0)
hist(BByr2_flwr$total_fruits)

BB2.param <- fitdistr(BByr2_flwr$total_fruits, "negative binomial") 
hist(rnbinom(865, size =0.124, mu=2.709))
hist(rpois(865, lambda=2.709))

#closed_fruits
#negative binomial is better
BB2_fruits<-subset(BB23_aster_a, total_fruits>0)
hist(BB2_fruits$closed_fruits)
BB2.param2 <- fitdistr(BB2_fruits$closed_fruits, "negative binomial") 
hist(rnbinom(271, size = 1.27, mu=7.29))
hist(rpois(271, lambda=7.29))

#mean_seeds_per_fruit
#negative binomial is better
BByr2_cl_fruits<-subset(BByr2_flwr, closed_fruits>0)
hist(BByr2_cl_fruits$mean_seeds_per_fruit)
BB2.param3 <- fitdistr(BByr2_cl_fruits$mean_seeds_per_fruit, "negative binomial") 
hist(rnbinom(264, size = 5.62, mu=3.41))
hist(rpois(264, lambda=3.41))
```

#Creating new rows for every fruit so we can subset the data twice
```{r}
expand_rows <- function(df) {
  # Create an empty list to store the expanded rows
  expanded_rows <- list()
  
  # Loop through each row of the data frame
  for (i in 1:nrow(df)) {
    # Extract the values of 'closed_fruits' and 'total_fruits' for the current row
    c <- df$closed_fruits[i]
    t <- df$total_fruits[i]
    
    # Create a new data frame with 't' rows if t > 0, otherwise just copy the row once
    new_rows <- df[i, , drop = FALSE] # Copy the row
    
    if (t > 0) {
      # Replicate the row 't' times
      expanded_data <- new_rows[rep(seq_len(nrow(new_rows)), t), ]
      # Assign 'closed_fruits' to 1 for the first 'c' rows, and 0 for the remaining
      expanded_data$closed_fruits <- c(rep(1, c), rep(0, t - c))
    } else {
      # If 'total_fruits' is 0, keep the row as it is
      expanded_data <- new_rows
    }
    
    # Add the new rows to the list
    expanded_rows[[i]] <- expanded_data
  }
  
  # Combine the list of data frames into a single data frame
  expanded_df <- do.call(rbind, expanded_rows)
  
  return(expanded_df)
}

# Apply the function to your data frame
expanded_BB_23 <- expand_rows(BB_23)

expanded_BB_23$total_fruits <- ifelse(expanded_BB_23$total_fruits > 0, 1, expanded_BB_23$total_fruits)

```


###Set up aster
```{r}
#subset the data to only Gen 1
BB23_aster_a<-subset(expanded_BB_23, Gen=="G1")

#using base r, because for some reason I had an issue with the select function
BB23_aster_a <- BB23_aster_a[, !names(BB23_aster_a) %in% "msm_all"]

#set the nodes for the aster graphical model as "vars". "Pods_collected" is the sub sampled node 
vars<-c("surv_to_flower", "F_plant", "total_fruits", "closed_fruits", "mean_seeds_per_fruit")

BB23_aster_a <- as.data.frame(BB23_aster_a)

#reshape BB23_aster_a to longform
BB23_aster <- reshape(BB23_aster_a,varying = list(vars), direction = "long", timevar = "varb",times = as.factor(vars), v.names = "resp")

#Check that the reshape worked 
nrow(BB23_aster)
nrow(BB23_aster_a)*length(vars)

#designate fitness variable as terminal node, "mean_seeds_per_fruit"
fit<-grepl("mean_seeds_per_fruit", as.character(BB23_aster$varb))
fit<-as.numeric(fit)
BB23_aster$fit<-fit

#check that "mean_seeds_per_fruit" is designated as the fitness variable
with(BB23_aster, sort(unique(as.character(varb)[fit==0])))
with(BB23_aster, sort(unique(as.character(varb)[fit==1])))

#Add a variable "root" to BB23_aster where value is 1
BB23_aster <- data.frame(BB23_aster, root=1)

#give each node a number
pred <- c(0,1,2,2,3)

#designate each node with a distribution. 1= Bernoulli, 2= poisson. sub sampling node (pods_collected) is binomial(Bernoulli is a type of binomial distribution so the family assignment is the same)
fam<-c(1,1,2,1,2)

```


###Random effects aster model
```{r}
####Fit random effects model. sire estimate is zero with dam  
Both_BB23<- reaster(resp ~ varb + fit + fit:Location, random = list(Donor = ~0 + 
    fit:Donor, Recipient = ~0 + fit:Recipient), pred = pred, fam = fam, varvar = varb, 
    idvar = id, root = root, data = BB23_aster)
summary(Both_BB23)

#Call:
#reaster.formula(fixed = resp ~ varb + fit + fit:Location, random = list(Donor = ~0 + 
#    fit:Donor, Recipient = ~0 + fit:Recipient), pred = pred, 
#    fam = fam, varvar = varb, idvar = id, root = root, data = BB23_aster)


#Fixed Effects:
#                           Estimate Std. Error z value Pr(>|z|)    
#(Intercept)               1.4857651  0.0523781  28.366  < 2e-16 ***
#varbF_plant              -0.8495700  0.1084814  -7.831 4.82e-15 ***
#varbmean_seeds_per_fruit -0.0830631  0.0550552  -1.509    0.131    
#varbsurv_to_flower       -1.7423210  0.0736260 -23.664  < 2e-16 ***
#varbtotal_fruits         -4.4942058  0.0698407 -64.349  < 2e-16 ***
#fit:Location             -0.0018710  0.0001975  -9.474  < 2e-16 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Square Roots of Variance Components (P-values are one-tailed):
#          Estimate Std. Error z value Pr(>|z|)/2    
#Donor      0.02899    0.02428   1.194      0.116    
#Recipient  0.09791    0.01174   8.337     <2e-16 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Check for the effect of sire alone. Significant. 
donor_BB23<- reaster(resp ~ fit + varb + fit:Location, random = list(Donor = ~0 + 
    fit:Donor), pred = pred, fam = fam, varvar = varb, 
    idvar = id, root = root, data = BB23_aster)
summary(donor_BB23)

#Call:
#reaster.formula(fixed = resp ~ fit + varb + fit:Location, random = list(Donor = ~0 + 
#    fit:Donor), pred = pred, fam = fam, varvar = varb, idvar = id, 
#    root = root, data = BB23_aster)


#Fixed Effects:
#                     Estimate Std. Error z value Pr(>|z|)    
#(Intercept)         1.4857651  0.0523781  28.366  < 2e-16 ***
#fit                -0.0471323  0.0546743  -0.862    0.389    
#varbF_plant        -0.8695883  0.1085041  -8.014 1.11e-15 ***
#varbsurv_to_flower -1.7423210  0.0736260 -23.664  < 2e-16 ***
#varbtotal_fruits   -4.5175262  0.0698658 -64.660  < 2e-16 ***
#fit:Location       -0.0018966  0.0001709 -11.100  < 2e-16 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Square Roots of Variance Components (P-values are one-tailed):
#      Estimate Std. Error z value Pr(>|z|)/2    
#Donor 0.068686   0.009384   7.319   1.25e-13 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#check for the effect of dam alone. significant  
recipient_BB23<- reaster(resp ~ fit + varb + fit:Location, random = list(Recipient = ~0 + 
    fit:Recipient), pred = pred, fam = fam, varvar = varb, #in model dam_ML19 shouldn't this say "fit:Dam"
    idvar = id, root = root, data = BB23_aster)
summary(recipient_BB23)

#Call:
#reaster.formula(fixed = resp ~ fit + varb + fit:Location, random = list(Recipient = ~0 + 
#    fit:Recipient), pred = pred, fam = fam, varvar = varb, idvar = id, 
#    root = root, data = BB23_aster)


#Fixed Effects:
#                     Estimate Std. Error z value Pr(>|z|)    
#(Intercept)         1.4857651  0.0523781  28.366  < 2e-16 ***
#fit                -0.0836726  0.0549512  -1.523    0.128    
#varbF_plant        -0.8495180  0.1084814  -7.831 4.84e-15 ***
#varbsurv_to_flower -1.7423210  0.0736260 -23.664  < 2e-16 ***
#varbtotal_fruits   -4.4941362  0.0698408 -64.348  < 2e-16 ***
#fit:Location       -0.0018646  0.0001971  -9.459  < 2e-16 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Square Roots of Variance Components (P-values are one-tailed):
#          Estimate Std. Error z value Pr(>|z|)/2    
#Recipient  0.10252    0.00963   10.65     <2e-16 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

####Combine Sire and Dam into one random effect, `Parental`. The estimates are of similar magnitude 
modmat.Donor <- model.matrix(~ 0 + fit:Donor, BB23_aster)
modmat.Recipient <- model.matrix(~ 0 + fit:Recipient, BB23_aster)
modmat.donorrecipient <- cbind(modmat.Donor,modmat.Recipient)


rout_BB23 <- reaster(resp ~ fit + varb, list(Parental = ~ 0 + modmat.donorrecipient),pred, fam, varb, id, root, data = BB23_aster)
sout_BB23 <-summary(rout_BB23)
sout_BB23

#Call:
#reaster.formula(fixed = resp ~ fit + varb, random = list(Parental = ~0 + 
#    modmat.donorrecipient), pred = pred, fam = fam, varvar = varb, 
#    idvar = id, root = root, data = BB23_aster)


#Fixed Effects:
#                   Estimate Std. Error z value Pr(>|z|)    
#(Intercept)         1.48577    0.05238  28.366  < 2e-16 ***
#fit                -0.16241    0.05563  -2.920   0.0035 ** 
#varbF_plant        -0.86097    0.10850  -7.935 2.11e-15 ***
#varbsurv_to_flower -1.74232    0.07363 -23.664  < 2e-16 ***
#varbtotal_fruits   -4.50767    0.06987 -64.512  < 2e-16 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Square Roots of Variance Components (P-values are one-tailed):
#         Estimate Std. Error z value Pr(>|z|)/2    
#Parental 0.084656   0.008331   10.16     <2e-16 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

save(rout_BB23, file = "rout_BB23.rdata")

#model comparison for significance of yloc. Significant.
rout_BB23_2 <- reaster(resp ~ fit + varb + fit:Location, list(Parental = ~ 0 + modmat.donorrecipient),
    pred, fam, varb, id, root, data = BB23_aster)
sout_BB23_2 <-summary(rout_BB23_2)
sout_BB23_2

#Call:
#reaster.formula(fixed = resp ~ fit + varb + fit:Location, random = list(Parental = ~0 + 
#    modmat.donorrecipient), pred = pred, fam = fam, varvar = varb, 
#    idvar = id, root = root, data = BB23_aster)


#Fixed Effects:
#                     Estimate Std. Error z value Pr(>|z|)    
#(Intercept)         1.4857651  0.0523781  28.366  < 2e-16 ***
#fit                -0.0787712  0.0557109  -1.414    0.157    
#varbF_plant        -0.8505911  0.1084831  -7.841 4.48e-15 ***
#varbsurv_to_flower -1.7423210  0.0736260 -23.664  < 2e-16 ***
#varbtotal_fruits   -4.4954193  0.0698428 -64.365  < 2e-16 ***
#fit:Location       -0.0019060  0.0001965  -9.701  < 2e-16 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Square Roots of Variance Components (P-values are one-tailed):
#         Estimate Std. Error z value Pr(>|z|)/2    
#Parental 0.076691   0.007683   9.982     <2e-16 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

anova(rout_BB23, rout_BB23_2)

#Analysis of Deviance Table

#Model 1: resp ~ fit + varb, ~0 + modmat.donorrecipient
#Model 2: resp ~ fit + varb + fit:Location, ~0 + modmat.donorrecipient
#  Mod Df Fix Mod Df Rand Mod Dev Df Fix Df Rand Deviance    P-value
#1          5           1 -7395.8                                   
#2          6           1 -7291.1      1       0   104.75 1.3837e-24

```

###Mapping function 
```{r}
#following Geyer et al. 2022

library(numDeriv)
fishinv<-solve(sout_BB23_2$fisher)
map.factory <- function(rout, is.subsamp) {
  stopifnot(inherits(rout, "reaster"))
  stopifnot(is.logical(is.subsamp))
  aout <- rout$obj
  stopifnot(inherits(aout, "aster"))
  nnode <- ncol(aout$x)
  if (nnode != length(is.subsamp))
    stop("length(is.subsamp) not the number of nodes in the aster graph")
  alpha <- rout$alpha
  ifit <- which(names(alpha) == "fit")
  if (length(ifit) != 1)
    stop("no fixed effect named fit")
  modmat <- rout$obj$modmat[1, , , drop = FALSE]
  # set root = 1
  root <- array(1, dim = dim(modmat)[1:2])
  x <- aout$x[1, c(1:5)] # added, 5 is the number of nodes 
  # return map function
  function (b) {
    stopifnot(is.numeric(b))
    stopifnot(is.finite(b))
    stopifnot(length(b) == 1)
    alpha[ifit] <- alpha[ifit] + b
    xi <- predict(
      aout,
      x = x, # added
      newcoef = alpha,
      modmat = modmat,
      root = root,
      model.type = "conditional",
      is.always.parameter = TRUE)
  
    xi <- matrix(xi, ncol = nnode)
    # always use drop = FALSE unless you are sure you don't want that
    # here if we omit drop = FALSE and there is only one non-subsampling
    # node, the code will break (apply will give an error)
    xi <- xi[,!is.subsamp, drop = FALSE]
    mu <- apply(xi, 1, prod) #every individual
    # mu is unconditional mean values for model without subsampling
    # in this application all components mu are the same because no
    # covariates except varb, so just return only one
    mu[1] 
  }
}

map <- map.factory(rout_BB23_2, vars %in% c("F_plant", "closed_fruits"))

#MEAN FITNESS
mf<-map(0)
mf
# 3.112505

#VA(W)
vaw <- rout_BB23_2$sigma["Parental"]^2 * grad(map, 0)^2
# get rid of name
vaw <- as.numeric(vaw)
vaw <- vaw * 4
vaw
#8.554372

####FFTNS
fftns <- vaw / mf
fftns
#2.748388

# get SE
map.factory.too <- function(rout, is.subsamp) {
  stopifnot(inherits(rout, "reaster"))
  stopifnot(is.logical(is.subsamp))
  aout <- rout$obj
  stopifnot(inherits(aout, "aster"))
  nnode <- ncol(aout$x)
  if (nnode != length(is.subsamp))
    stop("length(is.subsamp) not the number of nodes in the aster graph")
  alpha <- rout$alpha
  ifit <- which(names(alpha) == "fit")
  if (length(ifit) != 1)
    stop("no fixed effect named fit")
  # modmat for one individual. Taking the first row of modmat- there is one row for each individual
  modmat <- rout$obj$modmat[1, , , drop = FALSE] #this only takes the first row 
  # set root = 1
  root <- array(1, dim = dim(modmat)[1:2])
  x <- aout$x[1, c(1:5)] # added, second number is number of nodes 
  # return map function
  function (balpha) {
    stopifnot(is.numeric(balpha))
    stopifnot(is.finite(balpha))
    stopifnot(length(balpha) == 1 + length(alpha))
    b <- balpha[1]
    alpha <- balpha[-1]
    alpha[ifit] <- alpha[ifit] + b
    xi <- predict(
      aout,
      x = x, # added
      newcoef = alpha,
      modmat = modmat,
      root = root,
      model.type = "conditional",
      is.always.parameter = TRUE
    )
    xi <- matrix(xi, ncol = nnode)
    xi <- xi[,!is.subsamp, drop = FALSE]
    mu <- apply(xi, 1, prod)
    # mu is unconditional mean values for model without subsampling
    # Here Yloc was set to zero so there in only one value in the Xi matrix 
    mu[1]
  }
}

map.too <- map.factory.too(rout_BB23_2, vars %in% c("F_plant", "closed_fruits"))

#centering sire on zero
balpha.hat <- c(0, rout_BB23_2$alpha)

map.too(balpha.hat)
#3.112505

all.equal(map(0), map.too(balpha.hat))

#first and second derivatives
g<-grad(map.too, balpha.hat)

#calculates the nxn matrix
h <- hessian(map.too, balpha.hat)

#these are partial derivatives
dmu.db <- g[1]
dmu.dalpha <- g[-1]
d2mu.db.dalpha <- h[1, -1]

# give names to the estimators in our formulas
mu.hat <- map.too(balpha.hat)
nu.hat <- rout_BB23$nu["Parental"]

#FFTNS SE
#calculations for the gradient vector of the FFTNS prediction with respect to the parameters of the models (fixed effects and variance components) 
#zero removed
dfftns <- c(- 4 * nu.hat * dmu.dalpha * dmu.db^2 / mu.hat^2 +
8 * nu.hat * d2mu.db.dalpha / mu.hat, 4 * dmu.db^2 / mu.hat)

#And apply the delta method.
fftns.se <- t(dfftns) %*% fishinv %*% dfftns
fftns.se <- sqrt(as.vector(fftns.se))
fftns.se
#0.6824347

#ADDITIVE GENETIC VARIANCE SE 
#calculate the gradient vector VA(W) with respect to the parameters of the model using these formulae
dvaw <- c(8 * nu.hat * d2mu.db.dalpha, 4 * dmu.db^2)

#And then apply the delta method to get standard errors for this estimator
vaw.se <- t(dvaw) %*% fishinv %*% dvaw
vaw.se <- sqrt(as.vector(vaw.se))
vaw.se
#1.686604

#MEAN FITNESS SE
dmf <- c(dmu.dalpha, 0)
mf.se <- t(dmf) %*% fishinv %*% dmf
mf.se <- sqrt(as.vector(mf.se))
mf.se
#0.3113866
```

###breeding values
```{r}
bhat <- rout_BB23_2$b 
bhat.donor<- bhat[grep("Donor", names(bhat))]

#check this is the correct number of sires (44)
length(bhat.donor)

#convert canonical values to mean value parameter values using mapping function
map <- map.factory(rout_BB23_2, vars %in% c("F_plant", "closed_fruits"))
vectorized.map <- Vectorize(map)

#breeding values for sire groups on the mean value parameter scale 
bhat.donor.mu <- vectorized.map(bhat.donor)
bhat.donor.mu<-as.data.frame(bhat.donor.mu)
write.csv(bhat.donor.mu, "BB23_bhat.donor.mu.csv")
```

#BLUE OAK RANCH
##Generation 2 2023
```{r}
#subset the dataframe for the progeny generation
BB23_aster_b<-subset(expanded_BB_23, Gen=="G2")
BB23_aster_b<-droplevels(BB23_aster_b)
levels(BB23_aster_b$Gen)
```


```{r}
#total_fruits
#negative binomial is better
BByr2_flwr_b<-subset(BB23_aster_b, surv_to_flower>0)
hist(BByr2_flwr_b$total_fruits)

BB2b.prog.param <- fitdistr(BByr2_flwr_b$total_fruits, "negative binomial") 
hist(rnbinom(1319, size =514.082, mu=0.823))
hist(rpois(1319, lambda=0.823))
alpha.BByr2<-round(BB2b.prog.param$estimate[1],2)

#closed_fruits
#negative binomial is better
BB2_fruits_b<-subset(BB23_aster_b, total_fruits>0)
hist(BB2_fruits_b$closed_fruits)
BB2b.prog.param2 <- fitdistr(BB2_fruits_b$closed_fruits, "negative binomial") 
hist(rnbinom(1086, size = 504.591, mu=0.839))
hist(rpois(1086, lambda=0.839))
alpha.BByr2.2<-round(BB2b.prog.param2$estimate[1],2)

#mean_seeds_per_fruit
#negative binomial is better
BByr2_cl_fruits_b<-subset(BB23_aster_b, closed_fruits>0)
hist(BByr2_cl_fruits_b$mean_seeds_per_fruit)
BB2b.prog.param3 <- fitdistr(BByr2_cl_fruits_b$mean_seeds_per_fruit, "negative binomial") 
hist(rnbinom(911, size = 244.25, mu=4.35))
hist(rpois(911, lambda=4.35))
alpha.BByr2.3<-round(BB2b.prog.param3$estimate[1],2)
```

###Set up aster
```{r}
#establish nodes as vars. "pods_collected" is the subsampled node
vars<-c("surv_to_flower", "F_plant", "total_fruits", "closed_fruits", "mean_seeds_per_fruit")

BB23_aster_b <- as.data.frame(BB23_aster_b)

#reshape ML19_aster_b to long form
BB23_aster_g2 <- reshape(BB23_aster_b,varying = list(vars), direction = "long", timevar = "varb",times = as.factor(vars), v.names = "resp")

#Check that the reshape worked 
nrow(BB23_aster_g2)
nrow(BB23_aster_b)*length(vars)

#designate fitness node, "mean_seeds_per_fruit"
fit<-grepl("mean_seeds_per_fruit", as.character(BB23_aster_g2$varb))
fit<-as.numeric(fit)
BB23_aster_g2$fit<-fit

#check "Total_seeds" is designated as the fitness variable 
with(BB23_aster_g2, sort(unique(as.character(varb)[fit==0])))
with(BB23_aster_g2, sort(unique(as.character(varb)[fit==1])))

#Add a variable "root" to ML19_aster files where value is 1
BB23_aster_g2 <- data.frame(BB23_aster_g2, root=1)

#give each node a number
pred <- c(0,1,2,2,3)

#designate each node with a distribution. 1= Bernoulli, 2= poisson, subsampling node (pods_collected) is binomial which is the same family as Bernoulli
fam<-c(1,1,2,1,2)

#show graphical model
foo <- c("root", vars)
pvars <- foo[pred +1]
bar <-data.frame(pvars, vars, sapply(fam.default(), as.character)[fam])
colnames(bar) <- c("pred", "succ", "fam")
print(bar, right = FALSE, row.names = FALSE)
```

###fixed effect aster model
```{r}
BB23_g2 <- aster(resp ~ fit + varb + fit:Location, pred, fam, varb, id, root, data = BB23_aster_g2) 

summary(BB23_g2, info.tol = 1e-9, se.fit=TRUE)

#Call:
#aster.formula(formula = resp ~ fit + varb + fit:Location, pred = pred, 
#    fam = fam, varvar = varb, idvar = id, root = root, data = BB23_aster_g2)

#                     Estimate Std. Error z value Pr(>|z|)    
#(Intercept)         1.5262759  0.0784105  19.465  < 2e-16 ***
#fit                -0.0120949  0.0800235  -0.151     0.88    
#varbF_plant        -0.8581734  0.1641181  -5.229 1.70e-07 ***
#varbsurv_to_flower -1.9537199  0.1116374 -17.501  < 2e-16 ***
#varbtotal_fruits   -4.8419274  0.1050057 -46.111  < 2e-16 ***
#fit:Location       -0.0014041  0.0002085  -6.735 1.64e-11 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Original predictor variables dropped (aliased)
#     varbmean_seeds_per_fruit

BB_23_hyp <- subset(BB23_aster_g2, id == 1)
# set Location to 0
BB_23_hyp$Location <- 0
# set resp to 1
BB_23_hyp$resp <- 1

# predict conditional fitness estimates for this hypothetical individual
BB_23_hyp.p <- predict(BB23_g2, varvar = varb, idvar = id, root = root,
  newdata = BB_23_hyp, model.type = "conditional")

# take the product of these conditional estimates, EXCEPT for the sub sampling nodes (1st and 4th node)
mu.fit<-prod(BB_23_hyp.p[-2][-4])
mu.fit
#0.7493515
```

####mean fitness with negative binomial distributions
```{r}
#change the terminal node to negative binomial in the aster set up 
pred <- c(0,1,2,2,3)

#designate each node with a distribution
fam<-c(1,1,2,1,3)

#fam<-c(1,1,2,1,2)
famlist <- list(fam.bernoulli(),fam.negative.binomial(size = alpha.BByr2),fam.negative.binomial(size = alpha.BByr2.2), fam.negative.binomial(size = alpha.BByr2.3))
sapply(famlist, as.character)[fam] 
famlist

BB23_g2_b <- aster(resp ~ fit + varb + fit:(Location), pred, fam, famlist=famlist, varb, id, root, data = BB23_aster_g2) 
summary(BB23_g2_b, se.fit=T, info.tol=1e-9)

#Call:
#aster.formula(formula = resp ~ fit + varb + fit:(Location), pred = pred, 
#    fam = fam, varvar = varb, idvar = id, root = root, data = BB23_aster_g2, 
#    famlist = famlist)

#                     Estimate Std. Error  z value Pr(>|z|)    
#(Intercept)         1.526e+00  7.841e-02   19.465  < 2e-16 ***
#fit                -5.244e+00  8.001e-02  -65.546  < 2e-16 ***
#varbF_plant         2.339e+02  1.641e-01 1425.471  < 2e-16 ***
#varbsurv_to_flower -1.954e+00  1.116e-01  -17.501  < 2e-16 ***
#varbtotal_fruits    2.204e+02  1.048e-01 2102.063  < 2e-16 ***
#fit:Location       -1.401e-03  2.083e-04   -6.727 1.73e-11 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Original predictor variables dropped (aliased)
#     varbmean_seeds_per_fruit 

BB_23_hyp <- subset(BB23_aster_g2, id == 1)
# set Location to 0
BB_23_hyp$Location <- 0
# set resp to 1
BB_23_hyp$resp <- 1

# predict conditional fitness estimates for this hypothetical individual
BB_23_hyp.p <- predict(BB23_g2_b, varvar = varb, famlist=famlist,idvar = id, root = root,
  newdata = BB_23_hyp, model.type = "conditional")

# take the product of these conditional estimates, EXCEPT for the subsampling node (4th node)
mu.fit<-prod(BB_23_hyp.p[-2][-4])
mu.fit
#the estimate is not that different from the model with a poisson node 
#0.7492395
```

###estimate mean fitness and se 
```{r}
##This is using code from the switch-too-MR technical report 
#use poisson nodes 
#use the estimates from the hypothetical data frame where you set yloc to zero

#conditional
nnode <- length(vars)
nind <- length(unique(BB_23_hyp$id))
nnode * nind == nrow(BB_23_hyp)

pout.cond <- predict(BB23_g2_b, newdata = BB_23_hyp, varvar = varb, idvar = id, root = root, model.type = "conditional", is.always.parameter = TRUE, gradient= TRUE)
xi<-pout.cond$fit

class(xi)
length(xi)==nind*nnode

xi <- matrix(xi, nrow = nind)
colnames(xi) <- vars
xi

#unconditional
pout.unco<-predict(BB23_g2_b, newdata = BB_23_hyp, varvar = varb, idvar = id, root = root, gradient=TRUE)
mu<-pout.unco$fit
mu <- matrix(mu, nrow = nind)
colnames(mu) <- vars
mu

is.seeds<-grep("mean_seeds_per_fruit", vars)
is.fruits<-grep("total_fruits", vars)

is.seeds
is.fruits

#unconditional estimate of total fruits 
mu.fruits<-mu[, is.fruits]

#conditional estimate of total seeds 
xi.seeds <- xi[ , is.seeds]

mu.seeds <- mu.fruits * xi.seeds
mu.seeds
# Total_fruits 
#   3.633574

#make a  function
foo <- function(x) {
# x is xi and mu strung out as one vector
xi <- x[1:length(xi)]
mu <- x[- (1:length(xi))]
xi <- matrix(xi, nrow = nind)
mu <- matrix(mu, nrow = nind)
mu.fruits <- mu[ , is.fruits]
xi.seeds <- xi[ , is.seeds]
mu.seeds <- mu.fruits * xi.seeds
}

#vector of conditional and unconditional estimates for each node 
ximu <- c(xi, mu)
all.equal(foo(ximu), mu.seeds)

foo(ximu)
mu.seeds

library(numDeriv)
# R package numDeriv figures out the Jacobian matrix for this transformation.
#We also need the Jacobian matrix for the transformation from the “coefficients” vector to the vector ximu

jac.foo <- jacobian(foo, ximu)
jac.ximu <- rbind(pout.cond$gradient, pout.unco$gradient)
jac.total <- jac.foo %*% jac.ximu
#Now the delta method says the variance-covariance matrix of all the fitnesses (the vector estimate mu.fit) is JI−1JT, where J is the overall Jacobian matrix jar.total and I is Fisher information for the “coefficients” vector
#there are six coefficients from the model
V <- jac.total %*% solve(BB23_g2_b$fisher) %*% t(jac.total)
#and the standard errors are square roots of the variances (the diagonal elements of V)
se <- sqrt(diag(V))
bar.pois <- cbind(mu.fit, se)
colnames(bar.pois) <- c("Estimate", "SE")
bar.pois
# Estimate SE
# 0.7492395 0.2587203
```


Double-checking correlation between total_fruits and mean_seeds_per_fruit
```{r}
correlation <- cor(BB_22$total_fruits, BB_22$mean_seeds_per_fruit, use = "complete.obs")
print(correlation)

correlation <- cor(BB_23$total_fruits, BB_23$mean_seeds_per_fruit, use = "complete.obs")
print(correlation)
```